hello team and welcome back to the channel so before we start with the video I would request you subscribe to
0:10
the channel if you haven't already there are lots of amazing Hands-On videos on devops as well as on cloud devops so
0:16
make sure to subscribe to the channel now talking about the most awaited video on the channel that is complete
Architecture Flow
0:22
corporate cicd pipeline okay in this video we are going to do everything from
0:27
scratch so that even if you are developing in devop still you can implement the whole thing okay that
0:33
means we are going to set up our own infrastructure configure servers set up tools uh create kubernetes cluster right
0:40
we are going to create new private repository for source code push push the source code write pipeline get notified
0:47
and monitor the application okay so let me explain you the real flow how we are going to proceed so okay let us
0:52
understand the scenario we have a application and that application belongs to a client okay client says I want to
1:00
add some new feature for example client says I want to uh change the background color of the application so that is like
1:07
new feature right so client what he is going to do he's going to create a jira task or jira ticket that ticket will
1:14
contain detailed information about what changes needs to be done or what features needs to be added in the
1:20
application so that ticket will be assigned to a developer okay that
1:25
developer is going to write the source code and that source code he's going to test in his local machine if the source
1:32
code is running fine then he's going to push the new changes to the GitHub repository that contains the actual
1:38
source code once those changes are pushed into uh GitHub repository along with the source code then devop as a
1:45
devops engineer I will start writing the pipeline okay for writing the pipeline I'm going to use genkins okay so in
1:52
genkins first stage going to be compiling compilation of the source code this compilation is done to find out if
1:59
there is any syntax based errors in the pipeline or not okay after that is successful we are going to move to next
2:06
stage which is running of the unit test cases so we are going to run the test cases to find to test the functionality
2:13
of the code after that we are going to perform sonar Cube code quality check now code quality check is done to find
2:20
out if uh like if there are bugs issues or code smell or vulnerability inside the source code less those things are
2:27
inside our source code better is the quality okay after that we are going to perform a vulnerability scan on our source code
2:34
to find out if there is any sensitive data or also it this trivia tool is going to scan the dependencies of the
2:41
application if they are vulnerable if they are outdated or any other issue and it's going to generate a report now
2:49
generally on YouTube people usually like run the command to generate the report inside the console log so it's not a
2:55
good good practice because we cannot analyze it properly so in order to avoid this situation we are going to create
3:01
the report in a specific format and Export the report in a third party file
3:07
okay maybe in HTML or text file or anything that is like relevant after that we are going to build the
3:12
application or package the application to get the application artifact now this application artifact we are going to
3:19
publish to Nexus repository so that we can properly do release management with
3:24
different versions of the artifact okay after that we are once we have the artifact ready we are going to build the
3:31
docker image and tag it properly okay tagging is done basically to Define different versions of the docker image
3:37
after that we are going to use trivy again which is one of the most versatile tool in devops and using this trivy tool
3:44
we are going to scan the docker image to find out vulnerabilities in the containers okay after that we are going
3:51
to push the docker image to Docker Hub repository be it private or be it public
3:56
that depends on the project after that we are going to deploy the application right but before that we should make
4:03
sure that our kubernetes cluster is secure so for that we are going to use a tool known as cube audit that is going
4:11
to scan the kubernetes cluster and let us know if there are any specific issues in the cluster okay and final stage
4:18
would be to deploy the application to kubernetes Cluster and then we are going to verify the deployment if deployment
4:23
is sucessful or not right after that last stage in our pipeline is going to be mail notification we we are supposed
4:30
to receive the mail notification if pipeline is Success if pipeline is failed okay and finally once the
4:35
application is deployed then we are going to monitor the application now monitoring will be done in two ways
4:41
first we are going to use we are going to monitor basically website level monitoring using a blackbox exporter to
4:49
find out how is the traffic on the website website is up or not those kind of information and those monitoring
4:55
results we can see inside grafana also in order to teach you about the
5:00
system level monitoring basically to find out if there is like how much CPU is being used how much RAM is being used
5:07
so I'm going to monitor my genkins for that okay so for genkins I'm going to use node exporter for monitoring okay so
5:14
this whole process I'm going to teach you from scratch and implement it at the same time okay and as I mentioned again
5:22
all the scripts command and complete documentation will be in the telegram group so do not miss to join okay now
5:27
yeah so with that being said let's get started started with the hands on Cut te one more thing so batch 4 has started
5:34
and if you're interested in learning from scratch you can enroll to it the cost is somewhere around 6,500 after
5:40
using the coupon batch 4 okay and in this batch 4 we are going to cover everything from scratch course duration
5:46
is 2 months and you will be having access to batch three recordings also so you can watch those videos as well from
5:52
this beginning itself okay we are going to have live sessions on weekends and on weekdays I'm going to upload custom
5:58
recorded videos for you okay so yeah check it out links will be in the description okay team so first thing
Understanding the Phases Of Corporate DevOps
6:03
that we need to get started is like basically decide in what direction we are going to move on okay so okay so let
6:10
me explain you what we are going to do basically so we are going to proceed in multiple phases okay so phase one let's
6:17
talk about phase one so in Phase One what we are going to do first of all we need to have a
6:23
network envirment the reason for having a separate network envirment is that so that all the resources that we are going
6:29
to work with all the applications that we are going to deploy all those things should be private okay they should be in
6:38
isolated environment so that no outside entity should be able to access it
6:43
thirdly we are going to make sure that deployment and everything is secure these things we are going to do next up
6:50
we are going to have a kubernetes cluster or any other deployment cluster where we are going to deploy our
6:57
application okay so that also we are going to to setup thirdly we are going to create multiple virtual machines this
7:04
virtual Machin should also be created within a secure network and on these virtual machines we are going to set up
7:09
different servers and tools so servers we are going to set up like uh sonar
7:15
Cube server Nexus server tools like we are going to set up genkins right and
7:21
finally we are going to install monitoring tools which will be used for monitoring the application that we
7:26
deploy right so this will be the part of our Phase 1 where we are going to set up
7:32
the whole infrastructure okay talking about phase
7:38
two so in phase two we are going to create a git repository
7:45
okay and this git repository should be private so that no outside entity should
7:51
be able to access it okay so second is we are creating a g repository uh after
7:57
that we are going to push our source code to
8:03
it okay once we have Push once we have pushed our source code we should be
8:08
making sure that every like what whatever we have post it should be visible to us okay visible in repository
8:16
so that should be phase two phase three so when we talk about
8:22
phase three in this we are going to start working with the CI and CD
8:28
pipeline okay and when we are doing this we need to make sure that side by side we are
8:35
following the best practices and also we are taking
8:40
security measures so basically we need to make
8:47
sure that we are taking security measures so that everything is secure and correctly done okay so yeah and this
8:53
will be in uh phase three and phase three we are also going to configure mail notification
9:02
so that if our pipeline is success or failed we should be able to receive email notification that this is the
9:08
status of our pipeline okay and here itself after everything is done we are
9:13
yeah after before mail notification our deployment of the application will
9:19
be done okay now one step actually I missed in my phase one so once we create
9:25
this key test cluster we are also going to scan it for vulnerabilities or issues okay so we are going to use a
9:32
security tool for this okay as I mentioned ke everything that we are going to do we need to make sure that everything is secure and private okay
9:40
coming down to phase three yeah phase three is done now phase
9:45
four so in Phase 4 we are going to like set up monitoring tools and we are going
9:51
to monitor the application right now monitoring can be done on two levels one
9:57
is system level in syst level we can monitor things like
10:03
CPU we can monitor things like uh like Ram okay these kind of things we can
10:08
monitor and that is system level monitor second second kind of monitoring we can do will be website level okay where
10:16
basically we can like monitor traffic how much traffic is coming those kind of information we can monitor okay so these
10:22
two kind of monitoring we are going to do and this will be the four phases that we are going to follow right so now with
10:28
that being said let's get started okay so and as I mentioned everything we are going to do from scratch so make sure
10:36
you don't miss anything okay let me keep this pin tab separately
PHASE-1 | Setup INFRA [K8-Cluster Setup]
10:42
so I can work properly yeah okay so first thing that you need to do you need
10:48
to make sure that you have an AWS account and you are logged in and make sure that you are you have selected the region which is nearer to you for
10:55
example for me Mobile location is the nearest to me okay now talking about as
11:00
I mentioned we are going to make everything we are we need to make sure that we have a private Network
11:05
involvment right so basically for that what you need to do you can search here
11:11
VPC which is uh virtual private Cloud okay you can open it
11:18
so yeah if I open this VPC as of now you can see this is a default private uh
11:24
virtual private Cloud for me that exist but in companies as per the like instruction in which envirment we need
11:30
to create we can click on create VPC and create our own environment okay for me I'm going to use the default one and in
11:37
your account also there should be one default VPC which you can use you can you can just make sure that you are naming it correctly so that you can
11:44
identify afterwards okay and you don't need to change anything in this you can just go with default because yeah
11:50
everyone can have their uh private this is also a private one so we are going to go and use this okay moving forward we
11:57
can go to ec2 now whatever virtual machines that we are going to create we need to make sure that we Define key how
12:05
much it should be accessible from outside for that we can go to security groups so in Security Group basically
12:11
this is a kind of firewall for our resources okay so either you can create
12:16
a new one or you can simply use the default one but in default one also we
12:22
need to make some changes okay for example for me this is the security group that I'm using the primary one
12:27
okay and let me show you the ports that needs to be opened okay so you can take
12:33
a screenshot of this and you can understand okay these are the ports that you need to open in your Security Group
12:39
okay let me explain you certain ports that I have opened that are mandatory for me okay 30,000 to
12:46
32,767 this is a range that I have opened because the on when we like use Virtual machines as a kubernetes cluster
12:52
so this is the range that will be used for deployment of applications then we have Port 465
12:59
465 Port it is going to be used uh when we want to send mail notification from our Jenkins pipeline to ourself on our
13:06
Gmail address then for that this will be needed then we have 6443 now 6443 is
13:13
required when you set up your kubernetes cluster at that time this will be needed then we have S A such now when you
13:19
create virtual machines and you want to access those virtual machines then that is done through Port 22 okay then we
13:27
have for https 44 43 and for HTTP which is 80 then I have opened the range of
13:34
Port 3,000 to 10,000 because whenever I work with any applications most of them all like most of them can be easily
13:40
deployed within this range 3,000 to 10,000 okay so this is the range that I have opened then we have Port range okay
13:48
this is another SMTP server like for when we are want when we want to send email notifications over Gmail we are
13:55
using 465 but in general in companies they have this 42 which they use okay I
14:00
have just opened it but we are not going to use it okay so these are the range that these are the ports that you need to open in your Security Group okay now
14:08
once this is done then what we can do we can create multiple virtual machines which we are going to use so first let's
14:14
do one thing let us create uh one second let me create new virtual machines so
14:20
first what I'm going to do I'm going to create three virtual machines for our kubernetes cluster okay so for
14:27
kubernetes cluster also you know uh like kubernetes uh steps that were uh
14:32
existing for installation of kubernetes it has been like some issues occurring everywhere so recently only last night I
14:39
got I I just fixed it and yeah that is working fine now okay so I'm going to
14:44
take the virtual machine want to Sero 20.04 here I'm going to take uh 8GB or
14:52
maybe we can just go with four also because it is also more than enough okay
14:57
and here you can select the key if if you don't have the key pre-existing you can click on create new key pair provide
15:02
a name and click on create create new key pair now this key pair as soon as you click on create it will be downloaded on your local system okay
15:10
this key this key pair that I have it is also available on my local system now security group that I explained you to
15:16
open specific ports so you need to select those from here okay you can see
15:22
this is the launch wizard that I was showing you this is the security group that I showed okay configure uh space so
15:28
for stories I'm going to go with 25 click on launch instance now what I'm going to do uh let
15:36
me put it in this so let me name them immediately so first will be Master node
15:43
okay second will be uh slave node slave
15:49
one and third will be slave two okay so this is done now one by one what
15:56
we are going to do we are going to configure all of them okay so first of all uh let's do one thing copy the
16:03
public IP address of Master node now you need to make sure that you have one tool installed which is Moo xtm okay you can
16:10
download the home edition which is completely free you can download it this is the best tool when you want to work
16:15
with any virtual machines Windows Linux or any kind of virtual machine you can just work with it okay so I have
16:21
installed on my system I will open it as of now no changes have been done okay now in order to connect to your virtual
16:27
machine that you have created you need to click on session okay before that one more thing
16:33
I'll tell you which will help you a lot so make sure you go to settings then configuration okay uh SS such and here
16:41
you see this option SS keep alive make sure that you have checked it because if you don't then your virtual machines if
16:47
you leave it like for unattended for some time it will be disconnected from here so make sure that SSH keep alive is
16:53
on next thing click on session click on SSH then the public IP address that we
16:59
have copied for our Master node and since it is a virtual machine of uban 2 kind so username will be by default uban
17:06
2 okay so I have read wrote that now in order to connect to that virtual machine
17:11
using a private key I'm going to click on Advance SSS settings use private key
17:17
click on this to browse and this key that I have as I mentioned you once you create key here it will be downloaded on
17:23
your local so this is on my local right click on Open click on okay now what I'm
17:28
going to I'm just going to rename it so that I can identify later okay so this
17:33
I'm going to call as master and color I'm going to give it as uh blue
17:39
okay and let me just close this uh Now quickly I'm going to create a duplicate
17:46
of it and rename it to Slave 1 okay and for slave one the IP
17:53
address we need to change which will be if I go to instances running instance we have slave
18:00
one right so I'll copy this copy the public IP address and paste it here okay
18:07
click okay now this is also connected now again I'll create a duplicate session rename this this will be slave
18:16
two okay and we need to change the public IP address so I'll go here
18:22
instances uh slave two is this one copy this and paste it here
18:30
okay so all these three VMS have been connected now let's open them one by one
18:35
double clicking on them okay so next up what we need to do let's become a root
18:42
user on all of
18:52
them clear the screen on all of them and now we need to run commands to install
18:58
QB when it is cluster so as I mentioned I have just corrected everything last night only so it should be working fine
19:04
now okay so see uh like we have multiple command these many commands we need to
19:09
run so running them one by one it will be little hectic right so what I'm going to do I'm going to run them in groups so
19:16
till here I'm going to run them in one one group okay for that let me increase the size also so that you can see I'm
19:23
going to create a file shell script basically 1. sh
19:29
okay and I'm going to paste that all the commands that I have copied okay then
19:34
I'll save this file WQ and now in order to make sure that it
19:39
is executable we need to change the permissions as of now see for example if I run LS you can see 1sh file is there
19:47
so what I'm going to do I'm going to CH mod plus execute I'm adding the
19:52
executable permissions on the file okay that is done if I run LS you can see the color has been changed this
19:58
is because executable permissions have been provided now in order to execute this file I can simply type do/ file
20:05
name click enter and all the commands that I have wrote inside it will be running one by one okay now same thing
20:12
we are going to do on slave 2 also vi1 Dosh paste the commands here save this
20:22
file uh change the permissions to executable
20:30
and execute this okay now you can understand this ke how easier it becomes because obviously we cannot run one by
20:37
each command one by one that will take a lot of time right so for that we have this option like execute commands in
20:43
groups okay VI do 1. s for this is for slave 2 p the commands here and save
20:53
this and provide the permissions executable permissions Plus
20:59
X and file name will be this and execute it
21:04
okay now all this commands are executing one by one so here this is done here it's being done okay next set of
21:12
commands that we have it's going to be this okay so you can see basically see
21:17
kubernetes latest version is 1.29 right but I'm using just one less than that
21:23
because usually the latest version when you go with it it may have some issues okay so to avoid that kind of of things
21:29
I'm just going to go with one less than that okay now we have these commands so let us run one by one these are just one
21:36
or two commands right see basically what we did we added multiple packages so in order once as
21:42
soon as you add any new packages so for them to become available for usage you need to update it okay so I'll run the
21:49
command sud AP update on all these three machines
21:55
okay once that is done next we are going to install these Cube ADM Cube lit and
22:00
Cube CTL right Cube ADM is going to set up Cube anst cluster cubeit will be
22:06
responsible for creating the ports that we are going to uh like to which we are going to deploy applications and Cube
22:13
CTL will be the one basically working as a CLI for us to interact with kubernetes cluster okay so I'm going to copy this
22:20
this also we need to run on all three machines so let just run one by one
22:29
okay now till here whatever steps that I have run I have run on all three machines moving forward we are going to
22:36
run the commands only on Master node okay now here you can see pseudo Cube
22:42
ADM init p network cidr basically we are defining a range here in which uh our
22:48
like whatever deployment will will be done okay now this basically this range
22:53
that I have written here it has around 65,000 uh 35 six or something this is
22:59
the kind of like more than 65,000 addresses will be there which can be used for deployment okay so here also
23:05
based on your own requirement you can Define the uh like Network range okay so
23:11
now I'll copy that and I'll run it on the master node so what it's going to do it's going
23:18
to create a command which we can use to connect these uh slave one and slave two
23:25
and make them as cuberes worker node and on these Slave 1 and slave two machines our deployments will be done okay so I
23:33
have run this command on Master node let me write it here so that you
23:38
don't forget okay all this see all these documents
23:45
will be shared to you so do not worry okay and this commands we need to run on
23:52
Master node and worker node right okay coming back
23:58
here here so yeah let's wait for this to complete basically what it's going to do it's going to give us a command that we
24:04
can use and you can see here qadium join now this is a command that is going to be we need to execute it on the worker
24:11
node which we want to add as a see these two are the virtual machines right so we'll run these commands on these two
24:17
virtual machines to make them as the kubernetes worker node connected to the master node okay so I can copy this
24:24
whole thing and for authentication it has token okay now I'll paste it on the
24:31
slave one paste it on slave two
24:37
okay and let's wait and you can see here cubet uh this is like this node has
24:42
joined the cluster same thing we should be able to see on this seve to this node has joined the cluster we can get the
24:47
details here right now basically when you are setting up your kuet cluster you
24:53
should be you should make sure that you are saving this command because moving forward if you have any other thought
24:58
virtual machine which you want to add as a worker node you can run this command along with other two other other
25:03
commands and that you can make that virtual machine as the worker node okay after we have done that we need to
25:10
execute these commands also on Master node okay because this is going to create uh
25:15
basically we are creating a folder and that folder will contain this config file this config file is the conf
25:22
configuration file for kubernetes which contains all the information about kubernetes okay so that I'm
25:31
running copy this and paste it here okay now two final commands we need to run so
25:37
we need to run we need to install these two yaml files and create some resources B basically these these are some Network
25:43
related uh yaml files and which will be needed when we are working with like Network aspect of the kubernetes cluster
25:50
okay they'll be managing all those things so I will run execute these two commands
25:56
together okay and this should be done right so all the commands we have
26:02
run and now if I run this Cube CTL get nodes we should be able to see the
26:09
worker node this is the worker node one and this is worker node two okay if I see 71 right 71 this one and this is
26:19
104 you can see this is 104 so these two are the worker nodes okay and they are
26:24
ready for deployment so everything is done we have the kubernetes ready right now a very important thing that you
Security Scan Of K8 Cluster
26:31
should be knowing once you set up your kubernetes cluster what we can do we can scan the kubernetes cluster for any kind
26:37
of issues okay so for that there are multiple tools like triv also we have but trivy may not work
26:43
always so for that reason I'm just going to go with Cube AIT it is also a tool that can be used for scanning the cubus
26:50
Clusters okay so I'll open the releases which I want to
26:55
use and what I can do uh we have this uh AMD 64 right so I can right click copy
27:03
link address W get to download that paste it
27:09
here okay after that we are going to extract it and move the executable file
27:15
of that sorry about that some issue is there I guess okay so here we need to
27:24
change the name I guess and name is this
27:32
one okay now what we need to do we need to move this Cube audit executable
27:39
file let me copy this so this part I'm doing so that like as part of security
27:45
thing for our cluster okay and final command that we can run QB it all so if
27:50
I run this it's going to scan the whole cluster find different errors and all and yeah so this basically the the like
27:58
report that we are going to get that can be analyzed and used by infr team okay so yeah let it be it's being done it may
28:06
take few minutes because it's going to scan the whole cluster it's it found lot of things so since see you know there
28:12
there will be lots of issues coming now because we have still not yet set up everything like uh our back we have not
28:19
set up rule based access control like we have not created service account so because of that there will be issues coming but yeah it's good like we we can
28:26
get the results and this results can be analyzed by infra team okay so in this way we can use Cube AIT for security
28:32
measures also now so phase one uh out of phase one we have created uh Network
Create VMs for Jenkins, Sonar, & Nexus
28:39
environment is done kubernetes cluster is set up right next up we are going to create virtual machines so let's do
28:45
that instances running instance okay now let
28:50
me create okay team so next up what we are going to do is create virtual machines where we are going to configure
28:56
servers and some tools so I'm click on launch instance and
29:02
first uh create two instance which will be used for sonar Cube server and Nexus
29:07
server I'm going to use one2 server 20.04 and instance type I'm going to go
29:13
with T2 medium which is more than enough for both of them to work fine okay keyp we already have and network settings so
29:20
we already I already explained the ports that we need to open on the launch V uh on the any security group that you have
29:27
okay St storage I'm going to go with 20 which is uh more than enough for both of
29:32
them okay and let's do one thing uh let's go here pending let's rename them
29:38
first will be uh sonar Cube and second will be
29:48
Nexus okay uh next up what we can do we can connect to them one by one so I can get the public IP address go to mob xter
29:56
let's create a clone of this and click on rename rename this to sonar
30:03
Cube and paste the public IP address that we have right sonar Cube color I'll
30:09
be taking as Canan click on okay so sonar Cube configured now let us click on Sonar Cube server again and create a
30:16
duplicate session which we will uh rename to
30:22
Nexus color let me just take as uh green okay and public IP address so public IP
30:29
address we can get from where is it yeah this one copy the public IP address
30:35
paste it here you know see since it's to machine and key we are using same that's why we can simply go with creating a
30:41
clone and then configure that okay so now we have uh Nexus and sonar Cube created let me open them one by one okay
30:50
so this is good now next up what we what I what we are going to do is basically
30:56
set up uh create a virtual machine for genkins okay so as of now we have these
31:02
many virtual machines I'm going to create genkins and for genkins I'm going to take bigger resource okay here I can
31:10
give the server name as Jenkins and one 12 will be
31:15
20.04 scroll down at the here instance type I'm going to take at 8 gbb of ram
31:22
okay I have taken T2 large scroll down and this will be launch visard and here
31:30
I'm going to take a storage as 30 because lots of things we are going to do Okay click on click on launch
31:38
instance and genkins yeah let me get it pending now we can connect to Jenkins
31:45
also we can go to mobile XT create a clone okay and rename it rename it to
31:54
Jenkins and remote host will be public IP address of the genkins color I'll just go with red as we have for genkins
32:02
right click on okay so uh we have created like all these things
32:08
right and yeah sleve one and slave two we can just like close from here because they are already running and we don't
32:14
need to run any specific commands on slave one and slave two
32:22
okay yeah let me close this let me just one
32:29
time run this Cube CTL get notes just to make sure okay so notes are working fine
32:36
right okay now let's do one thing let's do uh let's set up one by one so R Cube and Nexus okay first thing that you
32:43
should always know that whenever you want to work with something uh when you want to connect to when you are connecting to a virtual machine First
32:49
Command that you should always run sud sudo AP update because you know uh if you want to use resources within the VM
32:56
uh from its Repository you need to update it so they are available for usage okay and we are going to use
33:03
Docker to set up the uh sonar Cube and an nexs servers so on nexs also I will
33:08
run sudo AP update right now we need to install Docker now installation of
33:13
Docker can be done in two ways for example if I run a command Docker you
33:19
see Docker is not found but we can get the commands to install it right this is one way but I wouldn't recommend it to
33:25
do so because uh there are certain PL also which which we which we may need
33:31
and we not that may not be available sorry about that that may not
33:36
be available in the Linux repository so what I'm going to do I'm going to go to Google and search here
33:43
install uh Docker and we are going to use the official command for installing
33:49
Docker okay so you can search this go to First Link scroll down and we have this
33:56
multiple steps right so I'll copy this whole thing and yeah obviously we are not going to run them one by one I'm going
34:02
to create a script let's call it as doc
34:08
Dosh and paste the script here let me see let me see everything seems
34:15
fine okay and let me save this uh P sudo CH mod plus X and yeah so
34:26
now let us execute it same thing we need to do on Nexus
34:32
server as well okay so VI doc
34:39
Dosh paste the whole thing save this and change the permission sud sudo
34:46
CH mod plus X okay do
34:52
slash Now commands are executing and Docker should be installed right sorry
34:58
uh package for Docker is added but Docker has not yet installed for installing Docker we need to run this
35:04
command okay now the reason that I was saying that we should be using official
35:09
documentation page for installation of Docker because you see it's not just installing docker.io
35:15
it is installing multiple things okay that's why I recommend to use this so
35:21
This command will install that and same thing we can do in Nexus
35:28
okay now Docker you know Docker is getting installed but the thing is key when you install Docker not all the
35:34
users will be having permissions to execute Docker commands only root user will be having by default so in order to
35:40
make sure that other users can also have permission to execute Docker commands we need to execute one small command which
35:47
is this one if I execute it then other than uh like root users also other users
35:53
can execute Docker commands right so I'll paste it here same thing we'll paste it here okay now
36:01
if I run uh try to run Docker command Docker uh
36:06
pull hello dasw we can see if Docker uh UB to user
36:14
is able to execute Docker commands or not and you can see it is able to execute now Docker is installed on both
36:19
the servers right so next up what we can do is create a Docker container for
36:24
sonar Cube and Nexus Okay so for creating a Docker container what we need to do we can run the command Docker run
36:31
that means we want to pull a container and pull a Docker image and create a container out of that Docker image okay
36:38
Docker run hyph d hyph d means that we want to run this all this process in
36:43
detached to mode that is in background okay hund and after that we need to provide we can provide a name so let's
36:50
say container name so I'm going to give it as sonar after that we can provide
36:55
the ports detail on which it should be running so first Port is 9,000 which is
37:01
for host Port host Port means the port that is going to be open on this virtual machine okay after that second Port I am
37:09
providing 9,000 again which is going to be the port of container so the container that is going to be created
37:15
within this virtual machine on that container this port will be open okay
37:20
and after that we need to provide the name of a Docker image which we want to use to create this container so I'm
37:25
going to provide a name so sonar Cube column and the tag or the specific
37:31
version you want to use so I'm going to go with LTS Das Community version which is a free version of sonar Cube click
37:38
enter and sonar Cube will fetch that like one two is going to download that image then it's going to create a Docker
37:45
container out of it okay if you want to like more versions of Docker image you can simply go on
37:51
Google search here as dockerhub okay that's first first page that opens
37:58
you can search here as let's say sonar Cube and you can find different Docker
38:04
images different versions whichever you want to use okay yeah so that is for done and and in
38:11
order to check if Docker container is created or not and it is running or not we can run this command Docker PS and we
38:17
can see Docker image is running with the name sonar which I gave right same thing let's do for Nexus with a different
38:24
image that is image for Nexus we can run Docker run hph D then name of the uh
38:31
container which will be Nexus and then Port so by default Nexus is supposed to
38:37
run on Port 881 so we are going to give both of them like container Port also 881 and host pools Port also 881 then we
38:46
need to provide the docker image name so Docker image name for Nexus is Sona type
38:52
slash Nexus sorry Nexus 3
38:58
and it's going to download see here I did not provide the tag or version so by default it took latest that means if you
39:04
don't provide the tag it is going to download the latest version and I'm fine with it right now soar Cube container is
39:11
created in order to access it what we can do right click here rename get the
39:17
public IP address of sonar server paste here and if you remember host Port was
39:22
9,000 click enter and you can see so cube is up so
39:29
the default username password for uh sonar cube is going to be admin and admin which we are going to change
39:35
afterward you can see it is asking to change the password so here we can write admin new password will be just adita
39:43
okay you can put anything you want I'm just putting my name now sonar Cube
39:49
server is set up and it is up and running now right now we can cancel this and we can check for uh Nexus Nexus is
39:56
also done so we can check by running command Docker PS and you can see here it is running with container ID and
40:02
everything right so to access this we can get its IP address which will be
40:07
Nexus uh rename IP address copy that and paste it
40:14
here colon 8081 right and you can see it is also getting
40:20
up but now there is a there is interesting thing that we need to understand if I click on sign on default
40:26
username is admin right but the password is located in Nexus
40:31
data in this specific file where do we get it so for getting it we can go to Nexus server we and our Nexus is running
40:39
inside a container right so we need to go inside the container by running this command doer exec exec means execute
40:47
then hyphen it hyphen it means interactive terminal that means I'm telling I'm saying that I want to
40:52
interact with a Docker container through a terminal right then after that it it Bic we need to Pro the information about
40:58
which container I want to interact with so I will put the container ID and then I need to proide the information like
41:03
what kind of terminal I want to use so I can go with bash slash sorry I can go
41:09
with bin SL bash that means I want to interact using bash terminal Okay click
41:16
enter now you can see here it is Chang right username change so that means ke I
41:21
am inside the docker container okay I can run LS command you can see all the files inside the docker container we can
41:27
go inside Sona type work you can see there is a folder Nexus right if I run
41:33
LS you can see the first file which is admin. password right so that we need to
41:39
get the get it we need to get the contents of it which I can do by running cat command and here you can see this is the
41:46
initial password till yeah till here we will copy because that is the uh username right copy that and paste it
41:53
here click on sign in and click on next new password so I'm
41:59
just going to go with Aditya same here Aditya Okay click on
42:05
next and I'm going to enable this Anonymous access as well okay you can get the details like uh uh what you want
42:13
basically in anous Access means default by default users can search browse and download components from repositories
42:19
without credentials if you don't want that you can simply disable it also okay but usually I just go with
42:25
enabling okay so now Nexus is set up and you can see here we have Nexus repositories also where we are going to
42:32
push different files which we want okay so Nexus is set up sonar cube is set up right let me clear the screen
42:39
exit Okay and sonar cube is also set up next step is to set up genkins right so
42:46
click on gen double click on genkins and as I have told you always always run the First Command Pudo AP
42:54
update okay so let it run and meanwhile we can get
43:00
the steps for installation of genkins how do we get okay meanwhile let me do one thing
43:07
uh let me add these steps for installation of uh okay I don't need toy
43:12
like I'll just add everything in the documentation page okay so you don't need to worry about that okay next up what we need to do so
43:21
for setting up genkins now what you need to understand that the prerequisite for genkins to run is that it it should be
43:27
having a Java right if I run here as Java we can see Java is not present but we got the commands to install Java
43:34
right so what I'm going to do I'm going to copy this command I'm going to install jdk 17 do not install any
43:39
version below it you will face different warnings or even issues so install 17 or
43:45
above okay so let me paste this paste here right and hyph Y so that no prompt
43:51
comes okay that is the prerequisite second we need to get the commands for installation of genkins you can simp L
43:57
go to Google and type install uh install genkins and you can it will take you to the official page of
44:04
genkins okay here you can see I I have chose to install for Linux you can select other versions also other other
44:10
like OS if you have Mac OS windows and anything else so for me I'm using uh like Linux version which is2 right click
44:17
on that and this is the command that we need to run so what I'm going to do I'm going to copy this command because I don't want to run one by one it's going
44:23
to be very hectic right so I'm going to write the that copy this whole thing and
44:30
let us do one thing let us create a script again vi just gen Dosh okay and I'm going to
44:38
paste all the commands here save this and uh change the permission which
44:45
we can do sud sudo and after sudo we can write sudo CH
44:52
mod plus execute the file name which we have right and I I can execute the file
44:58
now and this will start execution next thing what we can do we need to make sure that we have Docker also installed
45:03
on Jenkins because we will be running different Docker commands right so what I'm going to do I am going to get the
45:09
commands for Docker which I already have inside this right so I can copy this
45:14
whole thing and I can go to genkins okay so
45:19
let's wait for this to complete so that Jin Jenkins installation is done okay so
45:26
let's wait meanwhile if you haven't subscribed make
45:32
sure to subscribe team okay see because everything that I'm doing here is done like properly being
45:38
done and it's like it's the correct way to do things okay okay and jins is almost
45:46
up let's wait for a few seconds more okay so this is done let me clear
45:53
the screen now I'm going to install Docker which is going to be log.
45:58
s any any name you can provide to the script that does not matter okay and
46:03
save this and let me change the
46:08
permission X and execute this file right so once
46:14
this this command is getting executed one more thing that we need to do is execute this command to install the uh
46:21
Docker right and this is done iph y
46:27
our Docker is getting installed one more command that I mentioned we need to run is this one to give permissions to uh
46:34
other users then root okay so copy this yeah let's wait for
46:40
this to complete first by the way genkins is installed
46:47
Jenkins is installed we are installing Docker now right and yeah so this is
46:54
done now we can access jenin as well I can get the public IP address of
47:00
Jenkins uh from here copy the public IP address close this go to
47:06
browser paste it here and it is running on port 8080 by default
47:12
okay now here so in order to access genkins we need to get the contents of this initial admin password right so
47:19
I'll copy this and here we need to use Pudo because it's it will require elevated permissions I can run Pudo cat
47:26
and file details and this is the initial password for Jenkins okay so I will copy
47:32
this paste it here and click on continue now you see this option
47:38
customize Jenkins make sure that you click on first option because it is uh something that genkins knows which
47:43
plugins to install by default okay so just click on that and based on your size of the VM as well as your network
47:49
speed uh it may take few minutes okay so yeah I'll be back once this is completed
47:55
okay team so J is set set up and now we need to provide the username and other information so password also I'll just
48:01
keep as adity adya okay full name you can put and email address even fake email address you can put it does not
48:08
matter Okay click on Save and continue and save and finish so genkins
48:15
is set up right Next Step so basically phase one is complete we have uh
48:21
configured all these things we have set up CP address cluster we have set up all these things monitoring we are going to do it later okay phase two set up get
PHASE-2 | Git Repo
48:28
repo private get repo push the source code and make sure that repo is uh source code is available right so you
48:33
can go to your GitHub account this is my account make sure to follow me uh you will find lots of like projects full
48:38
stack projects you will be that will be really useful for you okay so let's do one thing click on
48:44
new and let's create a project I'm going to call this project as board
48:51
game okay yeah and I'm going to make sure
48:57
that this repository is private and click on create repository now this repository is
49:04
created right now what we need to do we need to clone this repository on our local and copy the source code and push
49:10
this source code to this repository right so what I'm going to do this is the https URL of the repository I'll
49:16
copy this now before you start doing anything this is the source code that I want to use okay before you start doing
49:23
anything you need to make sure that you have one tool installed on your Loc local machine which is git bash okay
49:29
it's a free tool that is used to work with Git repositories you can roll on the commands that you want get commit
49:36
get push anything okay so based on your OS you can install it for me I have installed for Windows okay as I say it's
49:42
free so this is the source code that I want to use right so I'll right click on it show more options and you see this
49:49
option open get bash here so I will click on this now this will open the git bash that I have on my system right so
49:57
for cloning the repository I can run the command get clone and the repository URL
50:03
right click on enter and let's see now you can see here he this since
50:10
we are doing this for the first time right so it is asking me to sign in so either you can use either of these of
50:16
two options or you can go with token my suggestion go with token because you can use the token afterwards also okay so
50:22
where do we get the token so for that you can go here on your browser on your get repos click on your profile go to
50:30
settings and here uh scroll down at the end you'll find this option developer settings click on that and then we have
50:37
personal access tokens so click on that and tokens classic and we are going to click on
50:43
generate new token the classic kind okay so you can provide any name like get uh
50:49
token expiration date you can select and then you can select the scope what level of permissions you want to give to your
50:55
token for for me usually I give all permissions except like delete packages or delete repo except those I give all
51:03
permissions but again that is completely based on requirement how much you want to give okay so based on your own
51:10
requirement or like whichever company you are working on uh So based on that uh you can decide okay so we'll generate
51:17
the token and make sure that you copy this token somewhere because you won't be able to see it afterwards okay so
51:25
I'll just paste it here now we have the token right so what I can do I can paste the token here click sign
51:32
in going back here and so now you can see we are able to clone the repository
51:38
now let us uh go inside that folder that got created right now what I'm going to
51:43
do I'm going to put all these files inside this folder board game this is
51:49
the repository okay so this is done once this is done you can run the command get
51:55
add to add all those files get commit hyphen M for message and the
52:02
message will be okay let me clear this uh yeah so message will be that uh
52:10
added Source Code by devop Shack anything you can write
52:18
it's like just for clarity you can write any message Okay click enter and then you can write get
52:24
push now this will push the source code to the private GitHub repository that we have okay so you can see this is done if
52:30
I go to the repository uh let me go to my repositories you have you can see this s
52:38
private and all the all this source code file that we have it is like push now right with the message that I wrote
52:44
correct so we just have one commment so it's good right so this part is done so
52:50
phase two is done now let us start with phase three where we are going to start with uh SI CD pipelines and everything
Configure Jenkins
52:58
okay so before we start writing the pipelines what we need to do we need to click on manage genin and we need to
53:05
install certain plugins which will be required for us to work with Okay so click on plugins and we have to install
53:12
lot of plugins actually first plugins let's search for jdk so we have this option Eclipse tan installer basically
53:19
when you have multiple genkins jobs which require different versions of jdk
53:24
then you can use this plugin to set up multiple versions of jdk for usage okay
53:30
after jdk I'm going to search for Maven for Maven I'm going to install this
53:35
plugin make sure you install this config file provider because it helps to create settings.xml file global settings file
53:41
those kind of files which will be required to use okay so install this and make sure that you have installing this
53:48
uh pipeline M integration because that also will be needed during the next step
53:53
okay so after these three plugins we are going to search for for sonar so I'm going to install this sonar Cube scanner
54:00
okay before we move ahead I want to explain certain something to you because lots of people get confused from that
54:06
okay let me explain you so for sonar basically we have two things one is
54:12
sonar Cube scanner second is sonar Cube
54:21
server okay now this thing that you see here this is sonar Cube server where the report is
54:29
going to be published okay and here that you see sonar Cube scanner so this is a
54:36
tool you need to understand this this is a tool which is going to perform the
54:42
analysis and it's going to generate the report okay and this report it's going
54:49
to be published to sonar Cube server okay so do not get confused between sonar Cube scanner and sonar Cube server
54:55
these two are two different things okay now coming back to what we are doing okay so sonar
55:04
scanner we have selected right after sonar Cube uh let me think what I need to install uh Docker also we need to
55:11
do so for Docker we are going to install Docker Docker pipeline or Docker build
55:17
step it's not it's not safe I guess so we are not so we are just going to set up Docker and Docker pipeline
55:23
okay and after this we need to set up kubernetes also kubernetes plugin
55:29
because we are eventually we are going to uh set up kubernetes so I'm going to set up kubernetes kubernetes CLI
55:36
credentials I don't think that it will be needed because this will be doing it for okay meanwhile yeah we can just set
55:43
up these four tool these four plugins okay and other than that I don't think
55:49
we need anything else but yeah if needed we'll just uh install it afterwards okay
55:54
once you click on install you can see it's saying uh it's basically getting installed in back end
56:00
okay so let's wait for this to complete and until unless we get some
56:07
warning that we need to restart genins we are not going to restart okay if we get some warning that we need to in uh
56:13
restart then only we are going to restart genkins okay so yeah let's wait
56:18
for this meanwhile yeah all the servers are running fine kubernetes also if I run
56:25
this notes are up and running they are ready right and you can see the version
56:31
1.28.18
56:57
and one by one scroll down to jdk first okay let's say I want to use jdk version 17 so I'm going to write the name 17 and
57:05
whenever you want to configure The Tool uh configure the plugin that you had installed you need to always go to
57:11
install automatically and here you see this option install from adop to.net this
57:16
this is visible because we have installed that plug-in okay so I'm going to go with
57:21
177 scroll down and you can actually you know you can actually set up multi versions you can provide the name select
57:28
install automatically okay and here you can select the specific version of the uh jdk you want to use okay but yeah we
57:35
are good with one jdk version for us it's fine next sonar Cube scanner so
57:40
here we are going to provide the name sonar Dash scanner version you can select whichever
57:47
you want I'm just going with latest scroll down to Maven so Maven I'm going to go with I'm going to name it as Maven
57:55
3 and version let's select uh anything you can select but I'm just going with 3.6.1
58:02
okay scroll down to Docker so here also we can configure we can create a name as
58:08
Docker install automatically add install or download from doer. and I'm going to go with
58:14
latest so this is done these tools are configured now right Next
58:20
Step so next step what we can do we can create the pipeline itself now right so
58:25
click on new and name will be board game okay and here uh Jin job
58:35
kind we can select as pipeline okay one thing one option is
58:41
missing here no issues I click on okay okay let me save this and let's go
58:49
to uh manage enin uh
58:54
plugins and available plugins and here we can search as
58:59
Maven I'm going to uh download this plugin as well so I'm going to click on
59:05
install let's wait for this because you know the genkin job
59:12
kind there are Maven options should also be available so if I go here click on new item you can see this Maven project
59:19
now it is visible right and that's what it was missing so we can open the existing project that we have created J
CICD Full Stack Pipeline
59:24
job click on configure and now we can start writing by plan right now I want to I want you to learn writing it from
59:31
scratch okay now discard old builds so this is a part of best practice I just want to keep two builds in my history so
59:39
that they don't occupy too much space okay scroll down and here see you can
59:44
write it from scratch that's fine but always I suggest go with the hello world this will generate a template for you
59:50
basically a skeleton for Jenkins pipeline which is going to be really helpful for you to work with okay let me
59:57
close this let me close install Docker also okay yeah meanwhile make sure to
1:00:03
subscribe if you haven't already okay okay so we have this pipeline skeleton ready now we can configure it as per our
1:00:09
own requirement so first of all what I'm going to do I'm going to copy and create multiple stages which we are going to
1:00:15
modify later okay okay this many stage is fine okay
1:00:23
so first thing you know like whenever you install a plugin for genkins and you want to use it in your pipeline you need
1:00:29
to Define it inside your pipeline in one way or the other okay so for doing that
1:00:35
what we can do we can write Tools in this format and uh two tools
1:00:43
I'm going to Define here Java and Maven so the format is first J uh tool type
1:00:48
Java is a tool type jdk tool name in single codes which will be jdk 17 that
1:00:54
is the name that I gave to jdk that I configured right for Maven name Maven
1:00:59
tool type is Maven and uh tool name that I configured was Maven 3 right for those
1:01:04
who are still getting confused from where this is coming let me show you again if I go to manage
1:01:10
genkins uh tools if you look closely here jdk 17 is
1:01:16
the name of the tool that I configured similarly for M also I have configured Maven 3 right so yeah that's where it
1:01:22
came from now first step that we are going to write is going to
1:01:28
be kit checkout basically because we want to
1:01:34
work with a project and that project needs to be present in jenkin's local workspace right so that means we need to
1:01:40
pull it so how do we do it so we can do it see if you don't know how to write command you can simply take help from
1:01:46
pipeline Syntax for every stage you want okay I open this pipeline syntax expand
1:01:52
it and search for G now here we need to put the repository URL which is in our case this one I'll copy this paste it
1:01:59
here Branch as you can see it's main okay let me put it here now one
1:02:06
very important thing you should understand that here you can see the code is 128 that means we have not provided
1:02:12
credentials repository is provided but we have not given credentials that's why it's giving 128 error if we provided
1:02:19
credentials but credential is wrong then it would be giving unauthorized or something like 401 403 something like
1:02:26
that okay second thing that you need to understand support for password password authentication was removed on August 13
1:02:32
2021 that means we cannot use password for cloning of the repository so what we
1:02:38
need to use we need to use the token that we have right now how uh where
1:02:44
exactly do we create the credentials right so credentials we can create let me explain you if I just okay leave this
1:02:50
if I just go to dashboard manage en kins here you see this option
1:02:56
credentials right click on global for Global scope of the credentials click on ADD credentials username so username I'm
1:03:03
going to provide my uh GitHub username which is jwal r246 right and password so instead of
1:03:11
password we are going to use token that we have just generated so I'll copy that token paste it here and ID in ID you can
1:03:18
write get Dash cred or any description you want but make sure that you edit the ID because if you don't edit the ID it
1:03:25
will generate some random number very long number which is very hard to remember but now we can uh use our own
1:03:32
ID which is good okay so click on create this is done now what uh let me close
1:03:37
this again I'll open pipeline syntax get and the repository URL which
1:03:44
will be this and branches main right now it's
1:03:49
giving 128 error if I select the credal that we just added the error is just gone right click on generate p script
1:03:56
and we have our first stage complete okay go back here and let us write this
1:04:02
so pipeline uh stage is done next stest that I want to perform is compile this source code now compilation is done uh
1:04:10
compilation is done to find out if there is any syntax based errors in our source code right so how do we uh do that so
1:04:17
for that you know like we want to execute Maven commands which is visually it's like a shell Command right so we
1:04:23
can in order to execute shell commands in genins we can we need to enclose the command inside shell how do we do that
1:04:30
so that we can do by running s double codes mvn compile mvn compile is the
1:04:37
command that I wanted to run now it's a shell uh shell command I need to run it as so I can enclose it inside shell okay
1:04:44
compilation is done next step I want to execute test cases okay so for that
1:04:50
basically I can again write the command inside shell sh mvn
1:04:56
test okay after that next step so next step basically what I want I want to
1:05:01
scan my file system basically scan the whole source code to find out the viabilities that may exist in the
1:05:07
dependencies that I'm using Okay talking about dependencies so if I scroll down at the end you can see this pom.xml file
1:05:14
so all the dependencies that is being used by this project are mentioned here okay so I want to find if there any if
1:05:21
there is any vulnerability in the dependencies okay also so if I I want to find if there is any kind of sensitive
1:05:28
data that is being stored in my repository so for that we can use this third party tool which is known as trivy
1:05:34
okay so name of this will be file system scan okay and steps so trivy you know
1:05:43
but default plug-in is not available for trivy so what I'm going to do I'm going to install trivy on this uh genkin
1:05:49
server itself I have the command somewhere let me see
1:05:57
should be somewhere here yeah so this is the command that we can execute on Jenkin server to set up trivy if I go to
1:06:05
genkin v.sh again see my suggestion to everyone
1:06:10
is that you don't need to execute every command one by one because it's like hectic so you can simply create a script
1:06:17
of it okay and then sud sudo CH mod plus
1:06:23
X and we have this uh name of this script right and now we can execute the
1:06:31
script now that's going to install trivy on our local machine on the genin server
1:06:37
basically so once this is done then we'll be able to execute trivy commands as well but again very interesting thing
1:06:44
I'm going to show you with respect to trivy let me just check if it is installed trivy hphone
1:06:50
version so we are installed 0.491 right coming back to genkins okay
1:06:57
now I can execute trivy so the trivy is going to generate a report right so if I just run commands like uh
1:07:05
trivy uh FS dot it's going to generate the report inside the console log which
1:07:10
is hard to analyze right so what I'm going to do I'm going to ask Tri to generate the report in a specific format
1:07:17
and Export it inside a separate file okay so trivy then FS then hyphen hyph
1:07:24
format I want to generate the report in a t table format okay and the file to which
1:07:30
it will be exported let's write it its name as tri-
1:07:36
fs- report okay HTML then the path which I want to scan
1:07:43
so I want to scan current directory so I'll just put a dot okay now trivy will
1:07:49
uh do this thing properly so after this is done we want to perform sonar Cube
1:07:54
analysis okay so I can write the name as sonar
1:07:59
Cube analysis okay
1:08:04
and now before we start with sonar Cube we need to configure sonar Cube server
1:08:09
sonar Cube scanner tool we have configured right but server we need to configure so let me save this pipeline
1:08:15
so that it does not get uh like lost I'll go to dashboard go to manag en
1:08:21
kins then we need to go to system right so here basically if I show you
1:08:30
yeah if I scroll down here we'll be able to see sonar Cube servers so here we can
1:08:36
configure sonar Cube server right and for authentication we'll be using a token so let us do one thing let me uh
1:08:43
go to manage genkins credentials so here we can add
1:08:48
the token which will be used for authentication right click on global for Global scope click on ADD credentials so
1:08:55
instead of username password we are going to select secret text okay now where do we get the token so that we can
1:09:01
get if I go to sonar Cube server go to Administration security users tokens and
1:09:08
here we can provide the name so I'll just write the name as sonar Dash token any name you can put it's fine Okay
1:09:14
click on generate copy this and we are going to paste it in our credentials name will be
1:09:22
sonar Das token same thing will be the description of this credential Okay
1:09:27
click on create this is done create click on again manage genkins and now we
1:09:32
can configure the H uh genin uh sonar Cube server inside Jenkins okay scroll
1:09:38
down to sonar Cube server click on ADD sonar Cube here let's provide the name as sonar and the URL so for URL we can
1:09:46
copy from uh like IP address to 9,000 okay and paste it here and make sure
1:09:53
that you are removing the last slash and here we can select the token click on apply so this is done great again we'll
1:10:00
go to dashboard and we can resume the writing of the pipeline scroll down and let me write
1:10:07
the steps for sonar Cube analysis so we need to write the steps inside the block
1:10:13
that will have the credentials and the server URL of the sonar Cube on which we were supposed to publish the report okay
1:10:20
so from where we can get the block you can click on Pipeline syntax expand this and scroll down you
1:10:25
will see this option with sonar involvement if you are installed all if you have installed all the plugins but
1:10:31
still unable to see this option just restart your genkins by going here type
1:10:36
restart something uh re restart click enter and this will resolve your issue
1:10:42
okay after restart you'll be able to see the option okay once you have uh opened this just do this generate the block
1:10:49
copy this and paste it here but still we need to modify it B
1:10:55
because uh we are not going to use the credential ID or for token okay okay so
1:11:01
we are going to remove this and we are going to provide just
1:11:07
single codes sonar now your question would be why we are doing this right because see B Because if you want to
1:11:13
access some server we need to have two things URL and password right username password right so instead of using
1:11:19
username password we are using token and we have the URL and we have already configured this if I go to manage
1:11:26
genkins go to system okay let's yeah scroll down so
1:11:34
here if you notice I have configured a server name with uh server with name sonar and URL is there and credential is
1:11:42
there so I just need to call this okay and I'm calling that as well right now
1:11:48
so now we can write the steps but as I mentioned in the beginning with geniss that whenever you want to use a tool
1:11:54
third party tool that is installed through plugin and you want to use it in your pipeline you need to Define it in one way or the other so we need to
1:12:02
Define sonar scanner tool basically okay how do we how we are going to do that so
1:12:07
we can create an envirment for it okay and inside environment we are going to Define that tool so I'm going
1:12:14
to create a variable scanner uncore home equal to
1:12:20
Tool then the tool name Tool name is sonar D scanner again this sonar Das
1:12:26
scanner we have configured in the tool section that's why we can write it here now once we have written this we can
1:12:32
simply go to sonar here and we can write the commands to execute the analysis how
1:12:38
do we do that s such and sorry sorry guys give me one
1:12:47
second so generally as you remember we write s double quotes right but here we
1:12:54
are going to write in of double codes triple codes why because you have multiple lines of code then in that case
1:13:00
you can like consider the whole block with three uh three codes okay now here
1:13:05
what we are going to do first call the variable that we have created which is scanner home right and any tool you any
1:13:12
tool you install so executable file of that tool will be existing inside bin
1:13:18
folder okay so inside bin folder we will be able to see sonar Das scanner now
1:13:24
this this is the executable file of sonar scanner tool and we want to use it
1:13:30
so we are calling it by providing the location of this execute table file right after that we need to add some
1:13:36
arguments which will be D sonar do project name name May in name and
1:13:44
capital okay and name will be board game okay similarly for uh another argument
1:13:52
we are going to provide hyund D sonar dot project key the name of project key
1:14:01
can be same as board game or it can be different but I just keep it same just for my EAS okay and yeah now we need to
1:14:09
write the next command in next line so I can just put a slash go next line and we are in the same block that's because we
1:14:16
are using uh three codes that's why we are in the same block so one last argument we are going to use D sonar
1:14:22
dot uh since it's a Java process so Java do binaries file location we need to provide that we can do usually it exists
1:14:30
inside Target folder but if you are still getting confused you can just put a dot and that that that will also work
1:14:36
fine and we can close this okay now this block is closed and we are uh this this
1:14:41
will perform the analysis right so after analysis is done we can also perform the
1:14:46
quality gate basically quality gate of sonar cube is something it is like a
1:14:53
conditions if I go to Quality gate section you can see these are conditions okay so if these conditions are passed
1:14:58
then we can say okay our code is fine it is of good quality right so how do we write the quality gate so for that first
1:15:05
of all we need to go to Administration configuration go to web Hooks and we need to create a web hook okay so web
1:15:13
hook name you can provide anything like Jenkins talking about URL so for URL you
1:15:19
need to write in this format okay genkins public ip/ sonar web hook okay
1:15:25
so let's do that and so Jenkins URL is this one paste it here slash and we need
1:15:34
to write sonar Cube web hook right so let's do
1:15:40
that okay this will make sure that you are able to execute this onar Cube quality gate properly click on create so
1:15:47
web Hook is created right now we need to write a stage for performing the sonar Cube analysis that we can do using this
1:15:55
step okay if I copy this past it here okay here we are we
1:16:03
are basically what saying ke if wait for Quality gate and about pipeline that should be the condition false okay so
1:16:08
the pipeline should not be Abed and here we need to provide the credential ID so credential ID we can just provide as
1:16:14
sonar Das token which we have created right so this is fine so after quality
1:16:21
sonar Cube analysis is done next step we can build the application so for building we can write build stage and
1:16:28
steps will be s double quotes mvn package okay so
1:16:36
yeah this is done right next is let me create multiple more stages so that also
1:16:41
team remember that no two stages can have the same name it's going to cause issues
1:16:48
okay okay so multiple stages we have created Now amn package is done next step would be to publish artifacts okay
1:16:57
uh publish artifacts to
1:17:02
Nexus so for doing that we need to configure certain things multiple things actually okay let me explain you
1:17:10
what okay it is expired let me just login again quickly
1:17:16
admin password will be adya okay click on sign in so we have signed in okay so
1:17:24
in order to sorry about that in order to publish our artifacts to Nexus what we need to
1:17:31
do is add the repository URLs in our pal file so first I'm going to add for MAV
1:17:37
releases and talking about where do we add how do we add we can just go to pom.xml
1:17:42
file expand it sorry go to end and you will find something this if you are not
1:17:48
able to find this section you can manually add it also okay so since it it is already available for me I will just
1:17:54
add here here so M releases okay as I I'm saying again if you are not able to
1:18:00
see this section you can simply copy this whole section keep it on your local and next time whatever repo you want to
1:18:05
add you can just add these things ID repo name repo URL then again for
1:18:10
snapshot repository rep uh repo name and repo URL okay same thing I'm going to do for M
1:18:17
snapshots I will copy this and I will paste it here okay
1:18:25
so this is done I will just commit the changes here so repository URL we have added right but still we have not yet
1:18:32
added the credential to access this U uh repository right how do we do that so
1:18:37
let me explain you if I go to dashboard go to manage enkin if you remember I installed the plug-in config file
1:18:44
provider when you install that plugin automatically this section will be installed managed files and this is the
1:18:50
section where we can create these uh credentials for those kind of things so
1:18:55
you can select either Global Maven Maven settings or if you are having like uh like nodejs based projects then you can
1:19:01
go with Json file also so lots of options available for us we are using Java so we'll go with global Maven okay
1:19:08
make sure you provide the ID to something that you can remember which in my case it's going to be global
1:19:16
settings Okay click on next and now this file
1:19:22
it's known as settings.xml file where we we are going to provide the credentials for accessing Nexus okay scroll down until you find
1:19:29
one option something like servers and you can see servers right so
1:19:35
let's do one thing let us provide or create the credentials for
1:19:42
this now here we can put the uh repository name or ID which is same
1:19:48
Maven Dash releases okay and username so for username we can provide the name as
1:19:57
admin okay while password which is going to be the uh just ad as we have set up
1:20:03
for our Nexus right this is for Maven releases we are going to create one for Maven snapshots as
1:20:09
well okay so here we can write that uh
1:20:16
snapshots and credentials will be same okay so this is good and we can save this now we can go back to dashboard go
1:20:22
back to board game click on configure
1:20:27
and here we can uh in publish to access we can write that okay so the command that we can use
1:20:34
is Maven deploy but that we are going to write inside a specific block so that we
1:20:40
can use the global settings file okay so we will take help from pipeline syntax
1:20:46
expand it go to end and you will find this option with Maven here you can select Maven jdk specific version which
1:20:52
you want to use and the settings file that we have configured my global settings that we configured right and
1:20:58
here since we have not configured any separate so it's showing use the default one okay just click concentrate and this
1:21:06
here we have the block ready that we can write here okay now we
1:21:11
need to write the command to deploy the application artifact to Nexus uh here in this block okay now we can write sh
1:21:20
double Cotes mvn deploy this is going to deploy the artifacts of this application
1:21:26
to Nexus okay right so this is done next step would be to build the docker image
1:21:33
right build and tag Docker image
1:21:40
okay so let me yeah now we need to write Docker commands here okay so that also
1:21:48
we can take help from pipeline syntax scroll down at the end with Docker registry select that and since we are
1:21:54
using a public Docker registy so we don't need to provide the URL but if you're using a private one you need to
1:21:59
provide the URL talking about credential so we need to add the credential also so
1:22:04
instead of going to credential section through manage genkins we can directly add it from here click on genkins and
1:22:11
now you need to Pro the dockerhub username and password so in our case it's going to be ad SW password is going
1:22:18
to be something okay an ID so I'll just
1:22:23
provide as Docker cred this is fine click on ADD and we can select it
1:22:31
from here okay Docker installation we can select this and this is the block inside which we are going to write the
1:22:37
docker commands but before we start doing that we should be creating a script and inside that script I'll be
1:22:44
writing the docker commands Okay now inside that script I'll paste the
1:22:50
block and let me remove
1:22:56
this and we can write the docker command as such now Docker file is already
1:23:01
existing on the root directory this is the docker file right so we need to
1:23:06
build it so we can write Docker build hyph t for tagging and
1:23:12
naming should be first your username slash any name you want which is going to be board Shack or anything you want
1:23:21
and column will be latest or any specific version and then you need to provide the path of Docker file in my
1:23:27
case it's on the root directory itself or the current directory so I'll just put a dot
1:23:33
okay second command so yeah so what we have done we have built our Docker image and we have tagged it next step would be
1:23:40
to scan the docker image before we uh before we push it to dockerhub
1:23:46
repository so for that also we can use trivy that is the best part about trivy we can use trivy for multiple
1:23:52
purposes Okay so so let me do one thing let me create here another stage which
1:23:58
we are going to call as Docker image scan Docker image scan okay and here
1:24:07
instead of this we can write image and here we need to provide the image name
1:24:13
which we want to scan and this is the image that we want to scan okay uh this is good Docker so once the
1:24:22
scanning is done next up you know what we can do we can push the docker image to our dockerhub
1:24:28
repository okay and let me write it and this will be stage name will
1:24:36
be push Docker image and here we can write Docker
1:24:42
push let's remove the dot okay now this is done right this is
1:24:49
good so after this part is done what we can do we can deploy the application to
1:24:54
kubernetes cluster okay so for deploying the application to kubernetes Cluster in
1:25:00
a proper when we talk about doing it in a correct way or proper way what we can do we can create a service account or we
1:25:07
can use rback okay for those who are not able to understand these things you can watch the kubernetes master class you
1:25:13
will understand kubernetes scratch from from scratch to advanced level okay so
1:25:19
now what we are going to do we are going to let me explain you through a diagrammatic structure then it will be much clearer to you as well right where
1:25:26
is my pen tab okay so let me open
1:25:31
this now so basically this is what we are going to do one second give me one second
1:25:38
guys I haven't slipped actually from quite some okay
1:25:43
okay one second give me some
1:25:49
time okay so this is what we we basically mean for our back
1:25:56
rback means rule based Access Control okay now think
1:26:05
let's say we have user one we have user two we have user three
1:26:11
in our project okay user one is the architect and like it has proper
1:26:16
knowledge user one is like medium level guy and user three is the intern or like
1:26:21
uh just very fresher guy okay so when we are working with kubernetes
1:26:27
we cannot give complete access to fresher or the intermediate level guy right so what we do we create roles
1:26:34
let's say this is rle one this is rle two this is role three so in role one
1:26:42
what we have given we have given cluster admin access that means like
1:26:48
complete complete access we are giving so this rule we can assign to this user
1:26:54
right second rule it's not cluster admin but it has good level of access good level
1:26:59
of permissions okay so this role we can assign to intermediate level guide role
1:27:05
three is it's like just read only access okay so that like even some like
1:27:13
intern guy or fresher guy is there he has just read one access he can just see the things it cannot modify or change
1:27:19
anything so this can be assigned to this user now this is what we what we mean by
1:27:25
rule based access control because this is a part of security concern we cannot give complete access to everyone so we
1:27:31
create rules and we assign to specific users okay so that's how it work and that's what exactly we are going to do
1:27:37
now for our deployment to make secure okay let me show you how we can do that
1:27:45
so first of all we need to create a service account okay let me save this this pipeline it's
1:27:52
becoming quite huge and and yeah okay so for doing that what we can do uh let me
1:27:58
go to my GitHub account repositories and here we can go to
1:28:05
something like eks complete should be there this one okay but but you don't need to worry you don't need to go here
1:28:11
and there you can just find everything in a telegram group documentation and everything okay yes step Cs and I'll go
1:28:17
down here create service account so first we are going to create a user okay and how
1:28:24
do we do so we'll go to our Master node I'm going to write create this file VI s
1:28:31
uh SVC do yaml okay and I'm going to paste the contents
1:28:37
here now let me explain here we are creating a service account separate user okay which we are going to use to
1:28:43
perform the deployment okay name of the user I'm creating as genkins and it's going to we are going to do the
1:28:49
deployment inside separate project or separate namespace you can say so that Nam space is name space is going to be
1:28:55
called as web apps okay so I will create this save this file okay and name space
1:29:02
is not yet created so let me create the Nam space Cube CTL create namespace and the name of
1:29:10
names space will be web apps okay this is done now we can execute the uh SVC
1:29:17
command the service account command so that it can service account can be created hctl apply hyph
1:29:25
F right and this is created inside the name space okay so service account or
1:29:30
user you can say we have created next is to create the role that I just explained you okay now this role is having
1:29:36
complete permissions to like get details list details watch it create update patch or delete that means it has
1:29:42
complete access that needs to be there for doing any deployment okay so I'm going to create another file which will
1:29:49
be VI ro. yaml okay paste the contents and
1:29:56
here again we have mentioned that we are creating this role for uh web apps okay
1:30:01
so I'll just save this and we can run Cube CTL apply hyphen f and it will be this
1:30:11
one right now again rule is done now we have created the service account or the
1:30:16
user and rule we have created now we need to assign this role to the service account so for that we have this bind I
1:30:23
will copy this and let us create another file which will be bind.
1:30:29
yaml and then we can paste the contents okay save
1:30:34
this and we can run this okay Cube CTL apply hyphen f bind. yaml now now
1:30:44
the user that we created the genin user now it is having the permissions to perform this deployment and everything
1:30:50
else okay now to do this now basically we want our genkins to be able to
1:30:56
connect to kuus Cluster right so for that we are going to create a token which will be used for authentication
1:31:02
okay so let me do that so I'll copy this yaml this is the yaml create this VI uh
1:31:10
secret. yaml paste the content and here we need
1:31:16
to change the name of service account in our case service account name is Jenkins right so click on okay save this and
1:31:23
here you can see we have not yet uh provided the name of uh Nam space okay
1:31:29
so if we have not provided the name of Nam space then what we can do we can run this command Cube CTL apply hyphen
1:31:37
f and here we can provide hyphen n for namespace which is web apps so see if in
1:31:45
our amble file we have not provided name of namespace then we can simply provide here so that the resource that we are
1:31:51
going to create it should be created within that namespace Okay click enter now this is also done
1:31:57
great yeah so next step uh what we can do we can run this command Cube
1:32:05
CTL uh describe secret and secret name was my secret
1:32:13
name which is inside web apps name space right now you see this details we
1:32:20
created but we are here we got the token which we are going to use as the authentication from Jenkins to
1:32:26
kubernetes okay so let me explain you how we are going to do let me save this go to dashboard manage en
1:32:34
kins credentials Global add credentials kind
1:32:40
will be secret text secret we can paste here and name will be
1:32:45
k8- G okay copy that as well for description and click on create right
1:32:55
now if I go back to here configure and now we can take help from pipeline
1:33:02
syntax here we can find something with respect to kubernetes let me see uh config multips this one we can
1:33:10
take Cube config credentials we can select cuber is server endpoint how
1:33:16
where do we get it so for that what we can do we can write
1:33:21
CD this one slash do Cube this is the folder inside
1:33:28
which we have this config file which we can run sorry which we can see the contents of it using cat
1:33:35
command okay now we have all the details about our cluster and this is the server endpoint which we need so I'll copy this
1:33:43
paste it here then we have cluster name right so cluster name also we should be
1:33:48
able to get somewhere uh uh uh cluster name is just I guess kubernetes
1:33:56
so I'll copy that paste it here then name space obviously we are going to use
1:34:01
web apps okay and click on generate now this is the block inside which we can write the commands to perform kubernetes
1:34:09
deployment okay scroll down and here we can write uh we can create
1:34:16
this block and this will be rename to deploy to
1:34:24
to cuber netus okay now let's do one
1:34:32
thing okay now here we can write the commands to execute the deployment but
1:34:37
let me save this but the thing is we are going we are supposed to use a manifest files which we do not have as of now so
1:34:44
let's do one thing we can create manifest files the thing is you know you can take any template and you can modify
1:34:49
it as per your own requirement so that it becomes the Manifest files for your specific project okay so what I can do
1:34:56
for example like this is one of my projects secret Center generator let me see so we have this deployment service
1:35:02
yam file right so what I'm going to do I'm going to copy this whole thing okay and I'm going to use it as a template
1:35:08
for my current deployment okay so let's open the current
1:35:15
repository and add file create new file this will be the content and let's
1:35:22
proide the name as deployment Das
1:35:27
service do yaml okay but here we are going to change certain things which
1:35:33
will be name will be let's say board game and that's what I'm going to right
1:35:41
everywhere uh app also will be board game app will be board
1:35:47
game containers name will be board game Docker image also we need to change
1:35:52
first okay but yeah a few things let me just change so that that's why I say see
1:35:57
you don't need to write everything from scratch you can just use the uh template and then you can work with it okay we
1:36:04
need to change the uh do Docker image also which we can get from here this is
1:36:09
the docker image for hours
1:36:15
right replace and now here you see image pull
1:36:21
policy that means it's going to when it's going to pull the docker image I have written as of now if not present
1:36:27
second thing that we can write we can also use like always we can write always
1:36:33
that means every time we run the deployment it's going to pull the image but obviously if the we want to use it
1:36:38
if the image is not present right so yeah but uh let's just go with always
1:36:44
okay and container Port the port on which our application should be running so in my case my application is supposed
1:36:50
to run on Port uh 880 how do I know it because that's what I have written in my
1:36:55
Docker file if I open it you can see expose Port 880 that means it is supposed to run on port 8080 okay coming
1:37:02
to next let me see if what else yeah this is port and this is Target Port so
1:37:08
that also you need to make sure it is written correctly okay and Port is basically the port on which your surface
1:37:14
is going to run Target Port is same as the container Port okay then I'm writing here type as load balancer so basically
1:37:22
this is the service type okay service type type can be of different types let me explain you that as well so that you
1:37:28
don't miss out that okay in kubernetes one second in kubernetes con communication
1:37:35
between ports or like access of the ports is going to happen with a resource that is known as service okay Service is
1:37:43
like General types we have like uh cluster IP load
1:37:51
balancer node port and yeah three we can consider Ingress is also there but these three
1:37:57
are the ones that we need to know as of now cluster IP is basically uh a service type which is used for internal
1:38:04
Communications so basically that means to that means that if someone wants to access a uh application pod they cannot
1:38:11
use cluster IP okay because it is just for internal purpose internal Communications from outside it cannot be
1:38:17
used load balancer so if someone want to access the uh application from outside
1:38:22
then we can use load balancer node board it can also be used for external uh
1:38:27
access but it's not the uh very uh useful way because it opens a port on on
1:38:36
worker node okay so I would suggest highly that we should always go with
1:38:41
load balancer and usually load balancer feature is available by default in all the uh Cloud platform based cuberes
1:38:48
clusters that we have so this feature is available by default in that so you can use it okay
1:38:53
now coming back so here we have everything is written correctly let me
1:38:59
check one time board game deployment replicas 2 so and
1:39:05
so okay so this seems fine we are using type load balancer and click on
1:39:12
Commit so this is done and let me just copy the name of this
1:39:17
file and we can write it here in s such
1:39:23
you will write Cube CTL apply hyphen
1:39:30
f and name of the depl yaml file right but one problem that you might be
1:39:37
thinking okay we have not yet installed uh Cube CTL on genkins then how it's going to run correct question and that's
1:39:44
what we need to do next we need to install Cube CTL on genkins now okay so
1:39:49
for that also we have the commands ready I can where is it
1:40:02
KSS yeah this is the commands that we are going to run so I'll copy the whole thing and I'll will execute this on my
1:40:09
genin server so let me create k.
1:40:16
s paste it here and save
1:40:21
this uh uh sud sudo CH mod plus
1:40:26
execute and this I want to give permissions right now this is going to install Cube
1:40:33
CTL on my genin server okay see these are the things that we need to do in order to connect uh to kubernetes right
1:40:40
that's why we have uh this Argo CD tool on which I have created Master Class also okay so yeah this is done and now
1:40:49
this should be our Command should be working fine Next Step that I want to perform form is basically check if the
1:40:55
deployment is done okay so that we can do using another command which will
1:41:02
be Cube CTL get
1:41:07
parts s Cube
1:41:13
CTL get SVC also we can Define here itself key we want to check the ports
1:41:19
inside uh web apps and and yeah same thing for
1:41:25
this yeah even though we see even though we have written the namespace here but just for knowledge purpose so that
1:41:31
everyone knows I'm writing it here okay and the stage name will be verify
1:41:38
the deployment okay
1:41:44
now after this is done I think we don't need a separate stage instead what we need to do is
1:41:51
configure the mail notification ifications correct now talking about mail notifications so as I explained you
1:41:58
previously in the beginning that we need to have specific Port open which is
1:42:03
465 right so yeah that Port is already open so how do we configure mail notification let me explain you that as
1:42:10
well so let me use one of my accounts here you need to go to manage
1:42:17
Google account you need to go to security
1:42:24
after that you need to go to twostep verification it will ask you to put the
1:42:29
password okay so let let's
1:42:37
put and once you login then you will get some option uh at the end it's like app
1:42:45
passwords so click on that and it's going to generate a uh application password which is different from your
1:42:51
account password because this cannot be used for logging into your account okay so let's provide the app name as Jenkins
1:42:58
click on create now this is the password that it created right now this password can be used for uh sending mail
1:43:06
notifications let me explain you how Okay so once we have created this we
1:43:11
will just uh leave it go to board your genkins click make sure that you save the uh deploy uh the pipeline that you
1:43:18
have written click on dashboard go to manage in Kins go to system
1:43:23
okay and scroll down till you find something as email notification here you have email
1:43:30
notification and we have extended email notification email notification is just Basics while extended one it has much
1:43:37
like uh much Fe much more features okay now let us configure it so first we need to provide SMTP server since we are
1:43:44
going to use Gmail so SMTP server for Gmail is smtp.gmail.com
1:43:53
okay SMTP Port as you remember we have opened 465 correct then click on
1:43:58
Advanced here you need to make sure that you click on use SSL and credentials so in credential click on ADD and over
1:44:05
genkins we can add in username we need to provide our email address okay a246 S3
1:44:14
gmail.com password the password that we have just generated okay and I have
1:44:20
saved it here right let copy this
1:44:26
paste it here and this will be mail credentials right copy this paste it
1:44:32
here and we can add it and now select that as well okay this is done scroll
1:44:38
down uh scroll down to email notification okay here we can write
1:44:44
server is smtp.gmail.com
1:44:49
and then in advance we can write uh SSL SMTP Port will be
1:44:56
465 and authentication so username and password we need to put here which is going to be
1:45:03
t246 gmail.com and again password so password we are not putting the real password we
1:45:09
are putting the application password which we have just created right so this is done and this seems fine let me save
1:45:16
this and we can test where is it here it got saved or not
1:45:23
let me
1:45:28
see okay it is saved great so we can do one thing we can test uh configuration
1:45:33
by sending email notification and I want to send my email notification to just sw2 46@gmail.com
1:45:43
test configuration email was successfully
1:45:50
sent we can check that as well
1:45:57
over Gmail we can go and we should be able to see you can see here test email one okay that means
1:46:05
email configuration is correct now what we are going to do we are one second let me save
1:46:11
this now we can write the commands steps inside our email okay sorry inside our
1:46:18
pipeline to get notification okay team so for the Post
1:46:24
notification section you need to make sure that you are writing it below the stages and this is the uh you can write
1:46:31
okay this is color based and here you need to make sure that you are changing the recip uh recipient uh email so for
1:46:39
me I'm just going to put my own okay and here if you look closely uh
1:46:46
from and reply to that means if I receive the email and if I try to reply to that email then that reply will be
1:46:52
get getting sent to the email okay correct one more thing we can
1:46:58
attach some reports also so we have triv report and I want to attach my uh let's
1:47:04
say where is it uh triv triv triv yeah so I want to uh this should be
1:47:11
image triy image so I want to attach my trivy image report every time this job
1:47:18
runs okay so that I can write here
1:47:23
correct once we have written this then we are good to go and every stage we have written first thing that I'm going
1:47:30
to do is copy this whole stage so that I don't forget to save this I'll just save it here so that uh
1:47:39
moving forward I can just share it to you as well okay and we can run this Pipeline and
1:47:46
let's see okay some syntax based error is there inir this is this spelling wrong is
1:47:53
there let me correct
1:47:59
it okay and yeah it should be good now so let us try
1:48:06
again pipeline has started and this might take little bit of time because we are running it for the first time and it
1:48:12
is going to install all the tools that we have mentioned in our pipeline okay so yeah let's wait and once this is
1:48:18
complete I'll be back okay team so seems the pipeline is success successfully executed and we
1:48:25
have everything ready we have six test cases also passed and the PIP plan is
1:48:30
quite big it seems but yeah this is the proper way to
1:48:36
do something correct and now talking about what things we did we generate as
1:48:42
part of our artifacts you can see here we have J jar file as artifact we have P file as an artifact also if I open this
1:48:49
file uh we can go to workspace and we have we should be having the trivy report as well so we have two reports
1:48:56
one is trivy HTML uh sorry which is the triv image report then we have triy FS
1:49:02
report okay and this they are in proper format in table table format okay coming
1:49:08
to our uh here we can see uh we have the
1:49:13
board game project also created inside uh sonar Cube if I open this we should be able to see the issues in detail okay
1:49:21
and suggestions also on all the issues how we can fix it great coming back to our project um yeah so this is good
1:49:29
right next thing talking about how we can access the application so here we can see uh we use
1:49:36
load balancer right load balancer type of service right but as I mentioned ke the service uh when you use a load
1:49:42
balancer service type in your selfhosted kubernetes cluster it may not work because by default we don't have them
1:49:49
when you want to use load balancer uh in uh like through default you can just use a cloud platform based kubernetes
1:49:55
service okay but still I use load balancer kind so that I can show you the format so when you use load balancer
1:50:03
automatically an URL will be generated here inside external IP address okay and using this uh URL you can access the
1:50:10
application but uh here we have this information also available using which we can access the application so this is
1:50:16
the host port and this is the container Port this is the port on which our application will be accessible
1:50:22
okay and yeah so let's do one thing uh copy this let's get the IP address of
1:50:29
the slave one and on it it should be deployed I will just copy this paste it
1:50:35
here and the IP address which should be this one right sorry the
1:50:42
port Okay click enter and we can see this is the application running now this
1:50:48
application is not very simple application it is cred based application which is using these many things okay if
1:50:55
I try to it has like username credentials configured bux bunny defic
1:51:00
duck for example if I go to login I can type bux
1:51:08
bunny okay and here we are uh logged in as a user okay I can go to homepage we
1:51:14
can add some information about some games Okay click on submit the board
1:51:20
game right and we can open this we can add reviews
1:51:25
also okay submit the review right so now we don't have option to
1:51:31
delete and we don't have option to edit as well right only the user with manager role can edit or delete the reviews so
1:51:38
I'll just log out I'll log in again and this time I'll log in with uh Daffy
1:51:47
Duck and now we have logged in with you manager rule right if I click on home
1:51:53
click on this click on you reviews so I can edit also I can delete also okay
1:51:58
that's one of the differences basically this application is all about cred operations cred means create read update
1:52:04
or delete okay those are the basic operations that you should get started working with if you want to like start
1:52:10
working with basic projects okay and yeah so that means we need to say that yeah application is working fine all the
1:52:16
things is working fine and it is able to be deployed also right and we have amazing pipeline that we which we have
Monitoring
1:52:22
created a big pipeline which covers everything now after that what I'm going to do after this I'm going to show you
1:52:28
how we can perform the monitoring okay so let's do that okay team so now let's
1:52:33
uh start with the monitoring part okay so for that I'm going to create another virtual machine which will be let's call
1:52:41
it as monitor okay and I'm going to take a one two machine size uh server will be
1:52:50
20.04 and instance type I'm going to go with uh T2 large would be fine but T2
1:52:56
medium will also work fine okay and key Security Group will be uh launch
1:53:03
visard okay storage I'm going to go with 20
1:53:10
okay so let's wait for this to come
1:53:16
up this is the virtual machine so I'll copy this IP address go here and and let me connect
1:53:23
to the newly created virtual machine as well as rename it
1:53:31
okay IP address will be the one that we just
1:53:36
created okay so let's wait for this uh this server yeah it is in running status
1:53:42
so we can try to connect to it and let's wait yeah so this is good
1:53:49
and let's uh uh let's start installation of like Prometheus grafana exporter all those
1:53:57
things okay sud sudo AP
1:54:11
update okay meanwhile this is this is done right so let us start by
1:54:16
installation of grafana okay so or first let us install Prometheus
1:54:23
so for installation what we can do give me one
1:54:29
second yeah so installation we can see like we can uh this is the package that we are going to use this is for Linux
1:54:36
right so I'll copy this and let us create a let us download
1:54:41
it okay using dou okay so this is done and you can see
1:54:50
we have the package so let us uh EXT ex ract it by using tar hyphen x uh VF okay
1:54:58
and the file name so this is also done correct so let
1:55:05
me remove the zip tar file we don't need
1:55:12
it dot yeah okay so we have this
1:55:17
Prometheus we will go inside it okay and we have all these files okay now this
1:55:23
file that you see here this is the executable file of Prometheus okay so I can once I as soon as I execute this
1:55:30
file automatically Prometheus will be start to run okay how do do how do I do it so do slash
1:55:38
Prometheus okay and make sure to put m per afterward because I want to run it in background Okay click
1:55:45
enter so now uh Prometheus is running in background and by default Prometheus will be running on on uh Port 9090 okay
1:55:54
so I can get the public IP address of the virtual machine which I have and let's try to access
1:56:00
it on Port 9090 and you can see Prometheus is up
1:56:06
and running now right so this is good second thing that we are going to do is install uh grafana okay so team next up
1:56:13
we will install grafana so we can go to this site graana.com SLG grafana download and we have the steps just
1:56:20
three lines we need to run okay and let us make it much easier so we'll run it
1:56:26
on this location okay and we are going to
1:56:31
download this T file and after that we can just de
1:56:39
package it so that grafana will start to run okay so let's wait for this to
1:56:44
complete
1:56:59
okay this is done and in order to start grafana we can execute this command you
1:57:05
can see here right so I'll just paste it and this will start grafana server and
1:57:11
by default grafana server will be running on Port 3,000 okay and now you
1:57:17
understand why usually I open the port range from 3,000 to 10,000 000 because those are the ports something that I use
1:57:24
on regular basis okay so grafana is also getting set up we can login by default
1:57:30
password which is admin okay username and password both are admin by default and we need to uh change them so let me
1:57:38
update by my own name Aditya Okay click on
1:57:46
submit so this part is also Done Right Next Step that we need to perform is
1:57:51
basically we need to install blackbox exporter which is going to be helping us to monitor the website okay so on this
1:57:59
web page prometheus. io/ download I can
1:58:04
search blackbox this one right so let's do one
1:58:12
thing uh let's download the uh Linux package okay and that also I'm going to
1:58:20
download on my virtual machine click
1:58:26
enter okay so this is done and now we are going to extract it
1:58:34
xvf this is done so now you see we have tar file also so we will remove the tar
1:58:40
file of blackbox which we don't need as of now okay great so we have these three
1:58:48
folders so now let us go inside blackbox folder okay
1:58:54
and now we have this executable f file of blackbox exporter so what I'm going
1:59:00
to do I'm going to uh start this okay that we can do by running dot
1:59:06
slash okay and do not forget to put m per so that it can run in background
1:59:11
okay and this has started and by default it will be running on Port 915 okay so just to make sure that it is
1:59:19
running or not we can check it by going on that Port I'll copy the IP address
1:59:25
paste it here and Port is N15 click enter and you can see it's running now
1:59:32
right so this is good let me close this so Prometheus grafana and black box
1:59:38
exporter all three are running but we need to apply certain changes right so this specific thing that you see this is
1:59:44
a specific section which we are going to add inside the prometheus. yaml file okay where do find that file so so we
1:59:52
have this Prometheus folder let us go inside it and here we can see the prometheus. yaml so let us edit this
2:00:00
file okay now in this file we are going to uh
2:00:06
the thing that we have just copied for blackbox from blackbox so we are going to copy that uh paste it here and make
2:00:13
sure from because we have copied from job section right job name so that part
2:00:18
you need to paste as per the uh identation indentation sorry okay and just paste
2:00:26
this and here we need to replace the IP address of the VM on which blackbox
2:00:32
exporter is running right so for blackbox exporter ipv address we can
2:00:38
copy from here to here this is the IP address okay paste it
2:00:43
here uh remove this and let us remove the HTTP also
2:00:52
sorry about that I think we don't need to put uh uh change anything here we
2:00:57
need to remove this because this is the different job okay let me remove this
2:01:05
quickly okay so we need to change the IP address this
2:01:11
one this is the IP address of blackbox okay so let me remove
2:01:19
WP okay now here you see Target so here we can provide the information about
2:01:25
what exactly do we want to monitor okay so in that section what I'm going to do I am going to put uh two things I'm
2:01:32
going to put prometheus. is the one of the website that I want to monitor let's say and second website is the website on
2:01:40
which my application is running right so this is the deployed application so I'm going to copy the URL of this
2:01:46
application and paste it here okay now this means that we can monitor our
2:01:51
applic so let me save this okay now we have saved this right
2:01:59
now basically what I'm going to do we need to restart Prometheus so what I can do I can run this command
2:02:05
pgp prometh yes okay so we can get the
2:02:11
uh ID of this uh process running so we can kill this ID 26 2 one okay and now I can restart the
2:02:21
uh Prometheus and do not forget to put m%
2:02:26
okay so Prometheus has restarted now okay now we can refresh the page of
2:02:34
Prometheus and here we can go to targets okay now here you see these
2:02:40
targets okay so this might take some time to get up and running you can see
2:02:47
uh one target is get got up and one is uh still in pending okay so let Let me refresh again and you can see both the
2:02:55
things are uh up and running okay and for this in inside end points we can see basically this is the target uh this is
2:03:02
the target which is our application the application is running on this URL correct and we can see the props also so
2:03:08
so these are some metrics that is being scrapped by blackbox exporter so this is good
2:03:14
right and yeah so now we have this ready
2:03:19
right next thing that we need to do uh uh we want to like add Prometheus as
2:03:25
data source inside our grafana okay so for that we should be able to see this
2:03:32
section data sources click on that click on add data source click on Prometheus and here we need to provide
2:03:39
the uh IP address of the Prometheus okay URL of Prometheus so I'll copy here copy
2:03:45
this paste it here okay scroll down at the end because
2:03:51
nothing else we need to change and we can see it is running fine okay it is able to be connected next thing we need
2:03:56
to do is click on import dashboard Now to create a dashboard what we can do uh
2:04:02
we what we can do we can search here uh Dash
2:04:08
board uh blackbox
2:04:15
okay sorry about that let me search again also team before we do that if if
2:04:21
I refresh Pro this page you can see it is like also uh probe is like going on
2:04:28
okay some issue is going on and whatever is like it is it going to be used for monitoring only and here we can search
2:04:35
uh blackbox uh
2:04:41
grafana dashboard okay and we can this
2:04:50
foter open this first one and here you can see the ID as well as Json so I'm going to copy the ID copy that ID paste
2:04:58
it here 7587 okay click on load scroll down and here we need to select the uh
2:05:04
data source in our case it's Prometheus click on import now let me change it to last five
2:05:11
minutes so all these information that you are seeing here different probes okay you can see this is for our
2:05:17
application status is up as duration prob duration and SSL expir it's giving
2:05:23
na because it's like uh we don't have that as of now okay and yeah so in this
2:05:29
way we can monitor this is this is completely related to http proofs okay
2:05:35
and you can see uh we are able to get the results and we can also change this to 5 seconds so that we can get the
2:05:41
results within uh like we can have a refresh rate every 5 Seconds okay in
2:05:47
here you can select the specific targets you want to monitor or whichever website you want to monitor for us we are
2:05:53
monitoring uh uh sample URL which is prometheus. and the website URL of our
2:05:59
own where our application is deployed correct so this is good and we can have
2:06:04
the more details as we move ahead okay so this is the website monitoring for
2:06:11
HTTP okay so this is good now I want to show you the uh like system level
2:06:17
monitoring how we can do okay so let me show you that okay team so yeah now you understood that how we can use blackbox
2:06:25
exporter to monitor the website right Next Step what I want to do let's say we have genkins right so let us do one
2:06:31
thing let us monitor genkins itself so two things we are going to do first go to manage genkins go to plugins and here
2:06:39
in available search for Prometheus okay and Prometheus metrix
2:06:45
you can see you can install it let's wait for this to complete
2:06:52
and you can see it requires restart so what we can do uh put a slash restart
2:06:59
here okay and we can restart the server and let's wait for this to restart it
2:07:05
meanwhile it is getting restarted what we can do we can go here Prometheus download page and you can see this is
2:07:11
the node exporter so I can copy the IP address for Darwin sorry IP address for Linux okay and go to the genin server
2:07:20
okay so let let's do one thing uh let us download
2:07:26
the package for node exporter here itself on genkins we are going to monitor the system metrics of mon
2:07:32
genkins okay so we have the package ready now we can extract it tar hyphen
2:07:40
xvf load exporter okay so once this is done uh let me delete the uh tar
2:07:50
file okay now we are left with the folder so let us go inside the folder and we have the
2:07:56
node exporter executable file here right so let's do one thing let us uh uh run
2:08:01
it and we can run it and make sure we are using % so that it runs in background now node exporter should be
2:08:09
started uh one second sorry sorry sorry
2:08:23
one second give me one second let me fix this uh uh uh P
2:08:30
crap node exporter okay okay I think this is executable
2:08:38
file it is supposed to run actually uh let me
2:08:43
see and m% okay now it has started and one more
2:08:48
thing that you can notice here it is running on Port 9100 okay so we can
2:08:53
access it and let us see I will get the IP address of chins wherever we have
2:08:58
installed this node exporter right and we can try to uh access it at
2:09:05
9100 and you can see it is running and if I click on metrix so it is getting the metrix also this is good right okay
2:09:13
next step that we need to do is basically one again let me see if Jenkins also
2:09:19
restarted yeah so let me log into
2:09:28
it okay and let us go to manage and
2:09:33
kins system and we should be able to see the
2:09:39
because we have installed the plugin so we should be able to see the options of uh Prometheus here let's see
2:10:00
yeah okay and here we have decided we have checked what we need to check okay
2:10:07
we can select like whatever we want to check we can select here okay so yeah we here we don't need to make any specific
2:10:13
changes next up what we need to do we need to add certain things inside the uh moning VM okay inside Prometheus
2:10:20
basically so let's do one thing let us go inside Prometheus folder we have the
2:10:26
yaml file right so let us edit this okay now what we can do we can add
2:10:36
the a new job okay so let me show you so
2:10:41
we have these two things where we need to uh we can add it as new J
2:10:48
okay and yeah so here you can see it is written Local Host 9100 okay instead we
2:10:55
we will write the IP address of Jenkins because we want to monitor Jenkins okay
2:11:00
so let me write it here and make sure you don't need you
2:11:06
don't need to put actually HTP and same thing we need to do here as
2:11:19
well and Jenkins is running on F 8080 right so let's put
2:11:25
that okay and this is good so I'm going to copy this and paste it somewhere
2:11:33
here okay uh this is Black Box
2:11:53
okay and this should be [Music]
2:11:59
good okay so let us save this and we need to restart Prometheus
2:12:05
so what I can do uh PP
2:12:12
Prometheus and we can kill this ID uh kill Prometheus that is running we have
2:12:17
the ID details right and we can now restart the Prometheus okay that we can
2:12:23
do using this command and ENT Okay click enter and Promethea
2:12:31
should be running in back now so let's
2:12:37
check refresh the page okay so uh these things are getting
2:12:45
up and it will take little bit of time and here we can see Jenkins is also
2:12:52
up and running Let me refresh it again and at this point all the uh exporters
2:12:59
that we have blackbox and node exporter all of them are up and running now okay
2:13:04
so this is good and also we are going to monitor genkins so here instance we have written this okay
2:13:11
now inside grafana we can create another dashboard so for searching the dashboard
2:13:17
we can search something like let's say I'll search shes node
2:13:24
exporter dashboard okay
2:13:30
and we can get the IP address sorry we can get the ID and go back
2:13:36
to sorry let me let me save this dashboard okay so One dashboard we have
2:13:43
saved right you can see One dashboard let us create another dashboard for system L monitoring and here I'll put
2:13:49
the IP address sorry here I'll put the uh ID of the dashboard okay scroll down
2:13:55
and here we can select Prometheus data source and yes now these details that
2:14:01
you see here these are all all from our Jenkins Jenkins machine
2:14:09
okay and yeah so now uh all these things that you are seeing here Ram uh system
2:14:14
load and everything that is coming from Jenkins and here also other details also you can get okay how much is being used Network
2:14:22
traffic everything we can see here memory info memory VM stat and everything else right so this is
2:14:31
good and at this point we have two dashboard created you can see one is node exporter for monitoring the system
2:14:37
level metrics of genkins and we have Prometheus blackbox exporter which is going to monitor the website itself okay
2:14:45
so this is good and yeah uh from your own side what you can try you can try to include node exporter for monitoring
2:14:53
your website okay it's not hard and it's it can be done very easily you can try
2:14:59
Okay so yeah try to do that and do let me know if you face any issue so this is how we can monitor our things okay you
2:15:07
can see it's like everything is working very fine and yeah it's good okay so